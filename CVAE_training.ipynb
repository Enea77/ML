{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMaeCCdzuYk/885RBozhHe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enea77/ML/blob/main/CVAE_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run to connect to Google Drive if files are save there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "C3Et8X7s2-gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure to use varsion 2.8.0 of tensorflow to replicate given results\n",
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "9Yg9YXF03hBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.__version__"
      ],
      "metadata": {
        "id": "yE-B0G1_3fvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io,transform\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import rotate\n",
        "from skimage.filters import gaussian\n",
        "import time\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "1eZt5YEQ432h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define CVAE and functions needed\n",
        "class CVAE(tf.keras.Model):\n",
        "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
        " \n",
        "  def __init__(self, latent_dim):\n",
        "    reduced_size = int(SIZE/8)\n",
        "    super(CVAE, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(SIZE, SIZE, 1)),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=128, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Conv2D(\n",
        "                filters=128, kernel_size=3, strides=(2, 2), activation='relu'),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            # No activation\n",
        "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
        "        ]\n",
        "    )\n",
        " \n",
        "    self.decoder = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
        "            tf.keras.layers.Dense(units=reduced_size*reduced_size*32, activation=tf.nn.relu),\n",
        "            tf.keras.layers.Reshape(target_shape=(reduced_size, reduced_size, 32)),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=128, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=64, kernel_size=3, strides=2, padding='same',\n",
        "                activation='relu'),\n",
        "            # No activation\n",
        "            tf.keras.layers.Conv2DTranspose(\n",
        "                filters=1, kernel_size=3, strides=1, padding='same'),\n",
        "        ]\n",
        "    )\n",
        " \n",
        "  @tf.function\n",
        "  def sample(self, eps=None, apply_sigmoid=True):\n",
        "    if eps is None:\n",
        "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "    return self.decode(eps, apply_sigmoid)\n",
        " \n",
        "  def encode(self, x):\n",
        "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
        "    return mean, logvar\n",
        " \n",
        "  def reparameterize(self, mean, logvar):\n",
        "    eps = tf.random.normal(shape=(latent_dim,))\n",
        "    #eps = tf.random.normal(shape=mean.shape)\n",
        "    return eps * tf.exp(logvar * .5) + mean\n",
        " \n",
        "  def decode(self, z, apply_sigmoid=False):\n",
        "    logits = self.decoder(z)\n",
        "    if apply_sigmoid:\n",
        "      probs = tf.sigmoid(logits)\n",
        "      return probs\n",
        "    return logits\n",
        "\n",
        "  def call(self,image):\n",
        "    #shape = image.shape\n",
        "    #shape = tf.convert_to_tensor(shape)\n",
        "    #image = tf.reshape(image, shape)\n",
        "    mean, logvar = self.encode(image)\n",
        "    z = self.reparameterize(mean, logvar)\n",
        "    predictions = self.sample(z)\n",
        "    return predictions\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        " \n",
        " \n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "  log2pi = tf.math.log(2. * np.pi)\n",
        "  return tf.reduce_sum(\n",
        "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "      axis=raxis)\n",
        " \n",
        " \n",
        "def compute_loss(model, x):\n",
        "  mean, logvar = model.encode(x)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  x_logit = model.decode(z)\n",
        "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "  logpz = log_normal_pdf(z, 0., 0.)\n",
        "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        " \n",
        " \n",
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "  \"\"\"Executes one training step and returns the loss.\n",
        " \n",
        "  This function computes the loss and gradients, and uses the latter to\n",
        "  update the model's parameters.\n",
        "  \"\"\"\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "def infrance(model,image):\n",
        "  mean, logvar = model.encode(image)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  predictions = model.sample(z)\n",
        "  return predictions\n",
        "\n",
        "def generate_images(model, epoch, test_sample):\n",
        "  mean, logvar = model.encode(test_sample)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  predictions = model.sample(z)\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        " \n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        " \n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        " \n",
        "  for i in range(test_sample.shape[0]):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(test_sample[i, :, :, 0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "def predict(model, inp_image, apply_sigmoid=True):\n",
        "  mean, logvar = model.encode(inp_image)\n",
        "  z = model.reparameterize(mean, logvar)\n",
        "  predictions = model.sample(z,apply_sigmoid)\n",
        "  return predictions[0,:,:,0]\n",
        "\n",
        "def get_testing_training_sets(image='20111206DF', size=64,n_images=10):\n",
        "    \"\"\"Reads an image file 'image' and crops it in 2*n_images samaller sections of size 'size'. Sections from the \n",
        "    top half are added in the training set while those from the bottom half are added to the testing set. \n",
        "    Trainign and testing sets are then returned as numpy arrays\"\"\"\n",
        "    training = []\n",
        "    testing = []\n",
        "    img = io.imread(image)\n",
        "    width = len(img[0])\n",
        "    height = len(img)\n",
        "    try:\n",
        "        img = img[:,:,0]\n",
        "    except:\n",
        "        pass\n",
        "    for i in range(n_images):\n",
        "        shift_y = np.random.randint(height/2,height-size)\n",
        "        shift_x = np.random.randint(0,width-size)\n",
        "        training.append(img[shift_y:shift_y+size,shift_x:shift_x+size])\n",
        "        shift_y = np.random.randint(0,height/2-size)\n",
        "        shift_x = np.random.randint(0,width-size)\n",
        "        testing.append(img[shift_y:shift_y+size,shift_x:shift_x+size])\n",
        "    return np.array(training), np.array(testing)\n",
        "\n",
        "def gaussian_blur(img,sigma):\n",
        "  \"\"\"Returns the Gaussian blurred version of the image 'img' with a sigma value of 'sigma'\"\"\"\n",
        "  return np.array(gaussian(img,(sigma,sigma)))\n",
        "\n",
        "def gaussian_blur_arr(images,sigma):\n",
        "  \"\"\"Applies the function gaussian_blur to all images in the set 'images'\"\"\"\n",
        "  a = []\n",
        "  for img in images:\n",
        "    a.append(gaussian_blur(img,sigma))\n",
        "  return np.array(a)\n",
        "\n",
        "def norm_max_pixel(images):\n",
        "  \"\"\"Normalizes each image in the array 'images' such that the pixel intensities are within a range of 0 to 1\"\"\"\n",
        "  a = []\n",
        "  for img in images:\n",
        "    img = img/np.max(img)\n",
        "    a.append(img)\n",
        "  return np.array(a)\n",
        "\n",
        "def preprocess_images(images, size, sigma):\n",
        "  images = gaussian_blur_arr(images,sigma)\n",
        "  images = norm_max_pixel(images)\n",
        "  images = images.reshape((images.shape[0], size, size, 1))\n",
        "  return images.astype('float32') #np.where(images > .5, 1.0, 0.0).astype('float32')"
      ],
      "metadata": {
        "id": "w4iY1JtB5BeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 64 #set the size in pixels of the training samples\n",
        "SIGMA = 2 #Set the Gaussian Blurring sigma value\n",
        "epochs = 200 #Number of epochs on which to train the CVAE\n",
        "latent_dim = 20 #Latent dimentions of the CVAE\n",
        "image_file = \"20111206DF2.jpg\" #Image file used to obtain the training sets\n",
        "path = \"\"#Path to image file\n",
        "training_set, testing_set = get_testing_training_sets(path+image_file,SIZE,1000) #get training and testing sets from secions of the input image"
      ],
      "metadata": {
        "id": "QWEmbqpO5Pzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Uncomment the lines below to use the provided training and testing sets\n",
        "\n",
        "image_file = \"20111206DF\"\n",
        "mix_training_set = np.load(path+\"raw_training_set_\"+image_file+\"_64.npy\")\n",
        "np.random.shuffle(mix_training_set)\n",
        "mix_training_set.shape\n",
        "\n",
        "testing_set = np.load(path+\"raw_testing_set_\"+image_file+\"_64.npy\")[:100]\n",
        "testing_set.shape\n",
        "\n",
        "\n",
        "train_images = preprocess_images(training_set,SIZE,SIGMA)\n",
        "test_images = preprocess_images(testing_set,SIZE,SIGMA)\n",
        "\n",
        "train_size = 16\n",
        "batch_size = 16\n",
        "test_size = 5\n",
        "\n",
        "train_dataset = (tf.data.Dataset.from_tensor_slices(train_images)\n",
        "                 .shuffle(train_size).batch(batch_size))\n",
        "test_dataset = (tf.data.Dataset.from_tensor_slices(test_images)\n",
        "                .shuffle(test_size).batch(batch_size))\n",
        "\n",
        "num_examples_to_generate = 16\n",
        " \n",
        "random_vector_for_generation = tf.random.normal(\n",
        "    shape=[num_examples_to_generate, latent_dim])"
      ],
      "metadata": {
        "id": "b9mZdLhI7rpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save raw testing and traininig sets \n",
        "np.save(path+\"raw_training_set_\"+image_file+\"_64.npy\",training_set)\n",
        "np.save(path+\"raw_testing_set_\"+image_file+\"_64.npy\",testing_set)"
      ],
      "metadata": {
        "id": "HPnn6xJaNnMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBVb32Lz27d4"
      },
      "outputs": [],
      "source": [
        "#Call the CVAE and set the desired size of the samples\n",
        "model = CVAE(latent_dim)\n",
        "model.compute_output_shape(input_shape=(1,SIZE, SIZE,1))\n",
        "\n",
        "# Pick a sample of the test set for generating output images\n",
        "assert batch_size >= num_examples_to_generate\n",
        "for test_batch in test_dataset.take(1):\n",
        "  test_sample = test_batch[0:num_examples_to_generate, :, :, :]\n",
        "\n",
        "generate_images(model, 0, test_sample) \n",
        "for epoch in range(1, epochs + 1):\n",
        "  start_time = time.time()\n",
        "  for train_x in train_dataset:\n",
        "    train_step(model, train_x, optimizer)\n",
        "  end_time = time.time()\n",
        " \n",
        "  loss = tf.keras.metrics.Mean()\n",
        "  for test_x in test_dataset:\n",
        "    loss(compute_loss(model, test_x))\n",
        "  elbo = -loss.result()\n",
        "  display.clear_output(wait=False)\n",
        "  print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
        "        .format(epoch, elbo, end_time - start_time))\n",
        "  generate_images(model, epoch, test_sample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model\n",
        "model.save(path+image_file.strip(\".jpg\")+'_Size{}_SIGMA{}_epochs{}_latentdim{}'.format(SIZE,SIGMA,epochs,latent_dim))"
      ],
      "metadata": {
        "id": "rZj9wthC4QO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}