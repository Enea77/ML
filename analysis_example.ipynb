{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuyr1QzVHg/VXb08l2/gCV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Enea77/ML/blob/main/analysis_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run to connect to Google Drive if files are save there\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVW0iU9l_Htc",
        "outputId": "38346336-cab0-45dc-853f-9d7837d9ff23"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make sure to use varsion 2.8.0 of tensorflow to replicate given results\n",
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "9Yg9YXF03hBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yE-B0G1_3fvI",
        "outputId": "80b5a035-031f-4e71-d7a8-8144fc1ac1e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from skimage import io,transform\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import rotate\n",
        "from skimage.filters import gaussian"
      ],
      "metadata": {
        "id": "M185oJKoIqsB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussian_blur(img,sigma):\n",
        "  \"\"\"Returns the Gaussian blurred version of the image 'img' with a sigma value of 'sigma'\"\"\"\n",
        "  return np.array(gaussian(img,(sigma,sigma)))\n",
        "\n",
        "def gaussian_blur_arr(images,sigma):\n",
        "  \"\"\"Applies the function gaussian_blur to all images in the set 'images'\"\"\"\n",
        "  a = []\n",
        "  for img in images:\n",
        "    a.append(gaussian_blur(img,sigma))\n",
        "  return np.array(a)\n",
        "\n",
        "def norm_max_pixel(images):\n",
        "  \"\"\"Normalizes each image in the array 'images' such that the pixel intensities are within a range of 0 to 1\"\"\"\n",
        "  a = []\n",
        "  for img in images:\n",
        "    img = img/np.max(img)\n",
        "    a.append(img)\n",
        "  return np.array(a)\n",
        "\n",
        "def preprocess_images(images, size, sigma):\n",
        "  \"\"\"Preprocesses each image in the array 'images' applying the proper blurring, normalization, and shape to each image\"\"\"\n",
        "  images = gaussian_blur_arr(images,sigma)\n",
        "  images = norm_max_pixel(images)\n",
        "  images = images.reshape((images.shape[0], size, size, 1))\n",
        "  return images.astype('float32') #np.where(images > .5, 1.0, 0.0).astype('float32')\n",
        "\n",
        "def get_predictions_from_model(model,images):\n",
        "  \"\"\"Returns an array of images 'prd' containing the prediction of each image in the input array 'images' from the CVAE model 'model'\"\"\"\n",
        "  prd = []\n",
        "  for i in range(len(images)):\n",
        "    prd.append(model.predict(images[i:i+1])[0,:,:,0])\n",
        "  return np.array(prd)\n",
        "\n",
        "def get_difference(images,prd):\n",
        "  \"\"\"Returns an array of images containing the difference of each image in the input array 'images' with its respective prediction\n",
        "  of the model in the input array 'prd'\"\"\"\n",
        "  a = []\n",
        "  for i in range(len(images)):\n",
        "    d = images[i,:,:,0] - prd[i]\n",
        "    #d = np.absolute(d)\n",
        "    a.append(d)\n",
        "  return np.array(a)\n",
        "\n",
        "def get_heatmap(images):\n",
        "  \"set all pixels with an absolute value lower than MAX_PIXEL to 0\"\n",
        "  return np.where(abs(images) < MAX_PIXEL,0,images)\n",
        "\n",
        "def get_avg_near_max(images):\n",
        "  \"\"\"Returns the average pixel intesity in an area of about a column size around the pixel with largest absolute value\"\"\"\n",
        "  a = []\n",
        "  for img in images:\n",
        "    xmax, ymax = np.unravel_index(np.argmax(abs(img), axis=None), img.shape)\n",
        "    s = 0\n",
        "    c = 0\n",
        "    for i in range(-CLMN_SIZE,CLMN_SIZE+1):\n",
        "      for j in range(-CLMN_SIZE,CLMN_SIZE+1):\n",
        "        try:\n",
        "          s += img[xmax+i][ymax+j]\n",
        "          c += 1\n",
        "        except:\n",
        "          pass\n",
        "    a.append(s/c)\n",
        "  return np.array(a)\n",
        "\n",
        "def crop_images(images, size=64):\n",
        "    \"\"\"Reads a list of image files 'images' and crops it in smaller sections of size 'size' with overlaps\"\"\"\n",
        "    arr = []\n",
        "    half_size = int(size/2)\n",
        "    for image in images:\n",
        "      img = io.imread(image)\n",
        "      width = len(img[0])\n",
        "      height = len(img)\n",
        "      print(width, height)\n",
        "      try:\n",
        "          img = img[:,:,0]\n",
        "      except:\n",
        "          pass\n",
        "      for j in range(0,height,half_size):\n",
        "        for i in range(0,width,half_size):\n",
        "          if i+size <= width and j+size <= height:\n",
        "            arr.append(img[j:j+size,i:i+size])\n",
        "        if j+size <= height: \n",
        "          arr.append(img[j:j+size,-size:])\n",
        "      for i in range(0,width,half_size):\n",
        "        if i+size <= width: \n",
        "          arr.append(img[-size:,i:i+size])\n",
        "      arr.append(img[-size:,-size:])           \n",
        "    return np.array(arr)"
      ],
      "metadata": {
        "id": "ba6Vw8TpIvjp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 64 #set the size in pixels of the training samples\n",
        "SIGMA = 2 #Set the Gaussian Blurring sigma value\n",
        "CLMN_SIZE = 6 #half the width of a column in pixels\n",
        "MAX_PIXEL = 0.2 #Describes the largest absolute value of pixel intensity in a bulk difference image\n",
        "\n",
        "epochs = 200 #Number of epochs on which to train the CVAE\n",
        "latent_dim = 20 #Latent dimentions of the CVAE\n",
        "image_file = \"20111206DF\" #Image file used to obtain the training sets\n",
        "path = \"/content/drive/Shareddrives/ML_Project/\"#Path to train image file"
      ],
      "metadata": {
        "id": "JcSPvo1gIyrs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load model\n",
        "model = tf.keras.models.load_model(path+'model_'+image_file.strip(\".jpg\")+'_Size{}_SIGMA{}_epochs{}_latentdim{}'.format(SIZE,SIGMA,epochs,latent_dim),compile=False)"
      ],
      "metadata": {
        "id": "dydNrJTkI1MG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crop image file used in training to get testing set in sections of size 'SIZE'\n",
        "files = [\"20111206DF.jpg\"]\n",
        "testing_set = crop_images(files,SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQmKtRHKOHAJ",
        "outputId": "afa4e518-b07d-42d1-cf34-07129fd68deb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Crop image files that you want to check for anomalies in sections of size 'SIZE'\n",
        "files = [\"20111206DF.jpg\"]\n",
        "data_to_test = crop_images(files,SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoVxZZ-EI34g",
        "outputId": "bf6e130f-4150-4764-de5a-7f5c62731d59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess the images\n",
        "bulk_images = preprocess_images(testing_set,SIZE,SIGMA)\n",
        "data_to_test_images = preprocess_images(data_to_test,SIZE,SIGMA)"
      ],
      "metadata": {
        "id": "Lo9pPonlI6dJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the model predictions\n",
        "bulk_prd = get_predictions_from_model(model,bulk_images)\n",
        "data_to_test_prd = get_predictions_from_model(model,data_to_test_images)"
      ],
      "metadata": {
        "id": "5sWZkoNNI8Jp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "plwnzoW9IT_9"
      },
      "outputs": [],
      "source": [
        "#Get the Average Near Maximum distribution of the bulk testing set\n",
        "bulk_ANM = get_avg_near_max(get_heatmap(get_difference(bulk_images,bulk_prd)))\n",
        "\n",
        "#Set the bounds to identify a bulk sample from the Average Near Maximum distribution of the bulk testing set\n",
        "limit_coefficient = 1.5 \n",
        "MIN_ANM = bulk_ANM.mean() - limit_coefficient*bulk_ANM.std()\n",
        "MAX_ANM = bulk_ANM.mean() + limit_coefficient*bulk_ANM.std()\n",
        "if bulk_ANM.std() == 0:\n",
        "  MIN_ANM = bulk_ANM.mean() -0.1\n",
        "  MAX_ANM = bulk_ANM.mean() +0.1\n",
        "\n",
        "#Get the Average Near Maximum distribution of the data_to_test\n",
        "data_to_test_ANM = get_avg_near_max(get_heatmap(get_difference(data_to_test_images,data_to_test_prd)))\n",
        "\n",
        "#Lable each image in the data_to_test as an Anomaly (True) or Bulk (False)\n",
        "data_to_test_labels = np.logical_or(data_to_test_ANM < MIN_ANM, data_to_test_ANM > MAX_ANM)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#percentage of defects found\n",
        "data_to_test_labels.sum()/data_to_test_labels.size*100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwVEP2XqPF2o",
        "outputId": "4ac8085c-3a21-422d-e588-2c9abf4fc791"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.546875"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Total number of defects found\n",
        "data_to_test_labels.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5S8KTjIPqxX",
        "outputId": "5515c058-e9a6-43b4-d661-7e983c9e00fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_zgidr-eaQWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}